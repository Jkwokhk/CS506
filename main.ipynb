{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bow(documents, max_features):\n",
    "    \"\"\"\n",
    "    Computes the bag-of-words matrix for the given documents.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: List of text documents.\n",
    "    - max_features: Maximum number of features (vocabulary size).\n",
    "\n",
    "    Returns:\n",
    "    - bow_matrix: Sparse matrix of shape (n_samples, n_features).\n",
    "    \"\"\"\n",
    "    # TODO: Implement me!\n",
    "    vectorizer = CountVectorizer(max_features=max_features)\n",
    "    bow_matrix = vectorizer.fit_transform(documents)\n",
    "    return bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(documents, max_features):\n",
    "    \"\"\"\n",
    "    Computes the tfidf matrix for the given documents.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: List of text documents.\n",
    "    - max_features: Maximum number of features to use.\n",
    "\n",
    "    Returns:\n",
    "    - tfidf_matrix: Sparse matrix of shape (n_samples, n_features).\n",
    "    \"\"\"\n",
    "    # TODO: Implement me!\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lsa(tfidf_matrix, n_components):\n",
    "    \"\"\"\n",
    "    Applies LSA (using TruncatedSVD) to the tfidf matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - tfidf_matrix: Sparse matrix from tfidf vectorization.\n",
    "    - n_components: Number of components to keep.\n",
    "\n",
    "    Returns:\n",
    "    - lsa_matrix: Dense matrix with reduced dimensions.\n",
    "    \"\"\"\n",
    "    # TODO: Implement me!\n",
    "    vectorizer = TruncatedSVD(n_components=n_components)\n",
    "    lsa_matrix = vectorizer.fit_transform(tfidf_matrix)\n",
    "    return lsa_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(df):\n",
    "  documents = df['review'].tolist()\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(df):\n",
    "  labels = df['voted_up'].tolist()\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words matrix:\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 12240941 stored elements and shape (193174, 1000)>\n",
      "  Coords\tValues\n",
      "  (1, 659)\t1\n",
      "  (1, 644)\t1\n",
      "  (1, 353)\t1\n",
      "  (1, 613)\t1\n",
      "  (1, 781)\t1\n",
      "  (2, 659)\t1\n",
      "  (2, 103)\t1\n",
      "  (2, 974)\t1\n",
      "  (2, 566)\t1\n",
      "  (2, 51)\t1\n",
      "  (3, 353)\t1\n",
      "  (3, 974)\t1\n",
      "  (3, 51)\t3\n",
      "  (3, 575)\t1\n",
      "  (3, 343)\t1\n",
      "  (3, 968)\t1\n",
      "  (3, 658)\t1\n",
      "  (3, 829)\t1\n",
      "  (3, 737)\t1\n",
      "  (3, 439)\t1\n",
      "  (3, 676)\t1\n",
      "  (3, 728)\t1\n",
      "  (3, 609)\t1\n",
      "  (3, 858)\t1\n",
      "  (3, 458)\t1\n",
      "  :\t:\n",
      "  (193173, 797)\t2\n",
      "  (193173, 321)\t1\n",
      "  (193173, 463)\t1\n",
      "  (193173, 218)\t1\n",
      "  (193173, 827)\t1\n",
      "  (193173, 304)\t1\n",
      "  (193173, 227)\t1\n",
      "  (193173, 311)\t1\n",
      "  (193173, 258)\t1\n",
      "  (193173, 241)\t2\n",
      "  (193173, 186)\t1\n",
      "  (193173, 573)\t1\n",
      "  (193173, 976)\t1\n",
      "  (193173, 717)\t1\n",
      "  (193173, 699)\t1\n",
      "  (193173, 760)\t2\n",
      "  (193173, 733)\t1\n",
      "  (193173, 223)\t1\n",
      "  (193173, 634)\t1\n",
      "  (193173, 745)\t1\n",
      "  (193173, 456)\t1\n",
      "  (193173, 457)\t1\n",
      "  (193173, 257)\t2\n",
      "  (193173, 540)\t1\n",
      "  (193173, 908)\t1\n",
      "TF-IDF matrix:\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 12240941 stored elements and shape (193174, 1000)>\n",
      "  Coords\tValues\n",
      "  (1, 659)\t0.3927349272193502\n",
      "  (1, 644)\t0.5173331748388696\n",
      "  (1, 353)\t0.19785073479048174\n",
      "  (1, 613)\t0.5866189284370509\n",
      "  (1, 781)\t0.4414283437834276\n",
      "  (2, 659)\t0.42487761072250263\n",
      "  (2, 103)\t0.4393148118695128\n",
      "  (2, 974)\t0.2685755903800615\n",
      "  (2, 566)\t0.7123289783756589\n",
      "  (2, 51)\t0.21664738816123194\n",
      "  (3, 353)\t0.08094419653967493\n",
      "  (3, 974)\t0.10156644886068851\n",
      "  (3, 51)\t0.24578673556306596\n",
      "  (3, 575)\t0.11567443956768092\n",
      "  (3, 343)\t0.24530392328778294\n",
      "  (3, 968)\t0.15723766124614333\n",
      "  (3, 658)\t0.12828532303231557\n",
      "  (3, 829)\t0.2944325959567267\n",
      "  (3, 737)\t0.20130766036181474\n",
      "  (3, 439)\t0.1101286762640589\n",
      "  (3, 676)\t0.2696551117024034\n",
      "  (3, 728)\t0.17264239899232453\n",
      "  (3, 609)\t0.1031973726440532\n",
      "  (3, 858)\t0.07593634866050662\n",
      "  (3, 458)\t0.08555020603597345\n",
      "  :\t:\n",
      "  (193173, 797)\t0.116128531944849\n",
      "  (193173, 321)\t0.04444254754062836\n",
      "  (193173, 463)\t0.06150817699716023\n",
      "  (193173, 218)\t0.05610550619038008\n",
      "  (193173, 827)\t0.06877582837875983\n",
      "  (193173, 304)\t0.048628896366201504\n",
      "  (193173, 227)\t0.06723614808170117\n",
      "  (193173, 311)\t0.05056940169693122\n",
      "  (193173, 258)\t0.06985253758563326\n",
      "  (193173, 241)\t0.10395330342654331\n",
      "  (193173, 186)\t0.04926239607931891\n",
      "  (193173, 573)\t0.053539626522675965\n",
      "  (193173, 976)\t0.046587617261183045\n",
      "  (193173, 717)\t0.0566530275921052\n",
      "  (193173, 699)\t0.06207033292979925\n",
      "  (193173, 760)\t0.10881625934361065\n",
      "  (193173, 733)\t0.0644519713032139\n",
      "  (193173, 223)\t0.06348329038355062\n",
      "  (193173, 634)\t0.0696728724422366\n",
      "  (193173, 745)\t0.0702730913594836\n",
      "  (193173, 456)\t0.06116174026301293\n",
      "  (193173, 457)\t0.05503586450607509\n",
      "  (193173, 257)\t0.13291920254693884\n",
      "  (193173, 540)\t0.06755271327226829\n",
      "  (193173, 908)\t0.06620995047120506\n",
      "LSA matrix:\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.06682179 -0.05244749 -0.08777809 ...  0.00353954 -0.06225762\n",
      "   0.05814671]\n",
      " [ 0.11532034  0.023753   -0.04526027 ...  0.04510052 -0.08453943\n",
      "   0.02572293]\n",
      " ...\n",
      " [ 0.42661569 -0.09368563 -0.13539546 ... -0.00161973  0.05002196\n",
      "   0.00729863]\n",
      " [ 0.3934097  -0.03029467 -0.06020287 ...  0.02863013  0.0116002\n",
      "  -0.03237533]\n",
      " [ 0.67525629 -0.04214057  0.03145483 ... -0.00542988 -0.02428517\n",
      "   0.08412495]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "documents = create_documents(df)\n",
    "labels = create_labels(df)\n",
    "bow_matrix = compute_bow(documents, 1000)\n",
    "print(\"Bag of words matrix:\")\n",
    "print(bow_matrix)\n",
    "\n",
    "tfidf_matrix = compute_tfidf(documents, 1000)\n",
    "print(\"TF-IDF matrix:\")\n",
    "print(tfidf_matrix)\n",
    "\n",
    "lsa_matrix = apply_lsa(tfidf_matrix, 100)\n",
    "print(\"LSA matrix:\")\n",
    "print(lsa_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(features, labels, n_neighbors=5, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains a kNN classifier, and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - features: Feature matrix (can be tfidf or LSA-transformed).\n",
    "    - labels: Ground truth labels.\n",
    "    - n_neighbors: Number of neighbors for kNN.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    \"\"\"\n",
    "    trainX, testX, trainY, testY = train_test_split(features, labels, test_size=test_size)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights='distance')\n",
    "    knn.fit(trainX, trainY)\n",
    "\n",
    "    predict = knn.predict(testX)\n",
    "    accuracy = accuracy_score(testY, predict)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(testY, predict))\n",
    "\n",
    "    return accuracy, knn  # we return the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_tree(X, y, test_size=0.2, max_depth=70):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains a Decision Tree classifier,\n",
    "    and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix.\n",
    "    - y: Ground truth labels.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "    - max_depth: Maximum depth of the decision tree.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    - dt_model: The trained Decision Tree model.\n",
    "    \"\"\"\n",
    "    # 1. Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # 2. Instantiate Model \n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        criterion='gini', \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1\n",
    "    )\n",
    "\n",
    "    # 3. Train\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Decision Tree (max_depth={max_depth}) Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_naive_bayes(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains a Naive Bayes classifier (MultinomialNB),\n",
    "    and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix (may not allow LSA features because negative values).\n",
    "    - y: Ground truth labels.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    - nb_model: The trained Naive Bayes model.\n",
    "    \"\"\"\n",
    "    # 1. Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # 2. Instantiate Model\n",
    "    nb_model = MultinomialNB()\n",
    "    # nb_model = GaussianNB()        # uncomment for lsa tfidf\n",
    "\n",
    "    # 3. Train\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgboost(X, y, test_size=0.2, n_estimators=300, max_depth=6, learning_rate=0.1, subsample=0.8):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains an XGBoost classifier,\n",
    "    and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix.\n",
    "    - y: Ground truth labels.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "    - n_estimators: Number of boosting rounds.\n",
    "    - max_depth: Maximum depth of each tree.\n",
    "    - learning_rate: Reduce overfitting.\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    - xgb_model: The trained XGBoost model.\n",
    "    \"\"\"\n",
    "    # 1. Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # 2. Instantiate XGB model\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "    )\n",
    "\n",
    "    # 3. Train\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"XGBoost (n_estimators={n_estimators}, max_depth={max_depth}, \"\n",
    "          f\"learning_rate={learning_rate}) Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, xgb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run everything\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m accuracy, model = evaluate_knn(\u001b[43mX_tfidf\u001b[49m, y, n_neighbors=\u001b[32m5\u001b[39m)\n\u001b[32m      8\u001b[39m acc_dt, model_dt = evaluate_decision_tree(X_tfidf, y, max_depth=\u001b[32m70\u001b[39m)\n\u001b[32m     10\u001b[39m acc_nb, model_nb = evaluate_naive_bayes(X_tfidf, y)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Run everything\n",
    "\n",
    "y = create_labels(df)\n",
    "\n",
    "bow_matrix = compute_bow(documents, max_features)\n",
    "X_tfidf = compute_tfidf(documents, max_features)\n",
    "X_lsa = apply_lsa(X_tfidf, 100)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "accuracy, model = evaluate_knn(X_train, y_train, n_neighbors=5)\n",
    "\n",
    "# acc_dt, model_dt = evaluate_decision_tree(X_tfidf, y, max_depth=70)\n",
    "\n",
    "# acc_nb, model_nb = evaluate_naive_bayes(X_tfidf, y)\n",
    "\n",
    "# acc_xgb, model_xgb = evaluate_xgboost(X_tfidf, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
