{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde4cef-2aff-4bb6-8820-b2d549bce30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b18df1-fbb5-4a9c-b8b9-84a4b338faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(features, labels, n_neighbors=5, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains a kNN classifier, and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - features: Feature matrix (can be tfidf or LSA-transformed).\n",
    "    - labels: Ground truth labels.\n",
    "    - n_neighbors: Number of neighbors for kNN.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    \"\"\"\n",
    "    trainX, testX, trainY, testY = train_test_split(features, labels, test_size=test_size)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights='distance')\n",
    "    knn.fit(trainX, trainY)\n",
    "\n",
    "    predict = knn.predict(testX)\n",
    "    accuracy = accuracy_score(testY, predict)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(testY, predict))\n",
    "\n",
    "    return accuracy, knn  # we return the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b0670-650d-4121-829c-4c27ea95d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_tree(X, y, test_size=0.2, max_depth=70):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains a Decision Tree classifier,\n",
    "    and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix.\n",
    "    - y: Ground truth labels.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "    - max_depth: Maximum depth of the decision tree.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    - dt_model: The trained Decision Tree model.\n",
    "    \"\"\"\n",
    "    # 1. Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # 2. Instantiate Model \n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        criterion='gini', \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1\n",
    "    )\n",
    "\n",
    "    # 3. Train\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Decision Tree (max_depth={max_depth}) Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6de43-0de1-4802-9f4c-59d51dad8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_naive_bayes(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset, trains a Naive Bayes classifier (MultinomialNB),\n",
    "    and evaluates performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix (may not allow LSA features because negative values).\n",
    "    - y: Ground truth labels.\n",
    "    - test_size: Fraction of data to use for testing.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy score on the test set.\n",
    "    - nb_model: The trained Naive Bayes model.\n",
    "    \"\"\"\n",
    "    # 1. Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # 2. Instantiate Model\n",
    "    nb_model = MultinomialNB()\n",
    "    # nb_model = GaussianNB()        # uncomment for lsa tfidf\n",
    "\n",
    "    # 3. Train\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Predict\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1971999-43f9-43dc-bec3-25e9aa3aaf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run everything\n",
    "\n",
    "accuracy, model = evaluate_knn(X_tfidf, y, n_neighbors=5)\n",
    "\n",
    "acc_dt, model_dt = evaluate_decision_tree(X_tfidf, y, max_depth=70)\n",
    "\n",
    "acc_nb, model_nb = evaluate_naive_bayes(X_tfidf, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
